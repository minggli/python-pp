{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Uniform, Delta\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.distributions.util import logsumexp\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "import pyro.optim as optim\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "# assert pyro.__version__.startswith('0.3.1')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://d2fefpcigoriu7.cloudfront.net/datasets/rugged_data.csv\"\n",
    "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df[\"rugged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS(nn.Module):\n",
    "    def __init__(self, num_params):\n",
    "        super(OLS, self).__init__()\n",
    "        self.linear = nn.Linear(num_params, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OLS(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.rand(1000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = x_data @ torch.tensor([[2],[-1], [1]], dtype=torch.float32) + torch.tensor(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 520445.4062\n",
      "[iteration 0100] loss: 513166.5625\n",
      "[iteration 0150] loss: 513060.3750\n",
      "[iteration 0200] loss: 513060.2188\n",
      "[iteration 0250] loss: 513060.2188\n",
      "[iteration 0300] loss: 513060.2188\n",
      "[iteration 0350] loss: 513060.2188\n",
      "[iteration 0400] loss: 513060.2188\n",
      "[iteration 0450] loss: 513060.2188\n",
      "[iteration 0500] loss: 513060.2188\n",
      "[iteration 0550] loss: 513060.2188\n",
      "[iteration 0600] loss: 513060.2188\n",
      "[iteration 0650] loss: 513060.2188\n",
      "[iteration 0700] loss: 513060.2188\n",
      "[iteration 0750] loss: 513060.2188\n",
      "[iteration 0800] loss: 513060.2188\n",
      "[iteration 0850] loss: 513060.2188\n",
      "[iteration 0900] loss: 513060.2188\n",
      "[iteration 0950] loss: 513060.2188\n",
      "[iteration 1000] loss: 513060.2188\n",
      "Learned parameters:\n",
      "linear.weight [[-4.3415810e-08 -4.8128971e-08 -4.6952252e-08]]\n",
      "linear.bias [0.9787512]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "num_iterations = 1000\n",
    "\n",
    "\n",
    "def main():\n",
    "    for j in range(num_iterations):\n",
    "        # run the model forward on the data\n",
    "        y_pred = model(x_data).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y_data)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        if (j + 1) % 50 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.data.numpy())\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    # weight and bias priors\n",
    "    w_prior = Normal(torch.zeros(1, 2), torch.ones(1, 2)).to_event(1)\n",
    "    b_prior = Normal(torch.tensor([[8.]]), torch.tensor([[1000.]])).to_event(1)\n",
    "    f_prior = Normal(0., 1.)\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior, 'factor': f_prior}\n",
    "    scale = pyro.sample(\"sigma\", Uniform(0., 10.))\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
    "    # sample a nn (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    with pyro.plate(\"map\", len(x_data)):\n",
    "        # run the nn forward on data\n",
    "        prediction_mean = lifted_reg_model(x_data).squeeze(-1)\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\",\n",
    "                    Normal(prediction_mean, scale),\n",
    "                    obs=y_data)\n",
    "        return prediction_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO(), num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    pyro.clear_param_store()\n",
    "    for j in range(num_iterations):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(x_data, y_data)\n",
    "        if j % 100 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_marginal = lambda traces, sites:EmpiricalMarginal(traces, sites)._get_samples_and_weights()[0].detach().cpu().numpy()\n",
    "\n",
    "def summary(traces, sites):\n",
    "    marginal = get_marginal(traces, sites)\n",
    "    site_stats = {}\n",
    "    for i in range(marginal.shape[1]):\n",
    "        site_name = sites[i]\n",
    "        marginal_site = pd.DataFrame(marginal[:, i]).transpose()\n",
    "        describe = partial(pd.Series.describe, percentiles=[.05, 0.25, 0.5, 0.75, 0.95])\n",
    "        site_stats[site_name] = marginal_site.apply(describe, axis=1) \\\n",
    "            [[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats\n",
    "\n",
    "def wrapped_model(x_data, y_data):\n",
    "    pyro.sample(\"prediction\", Delta(model(x_data, y_data)))\n",
    "\n",
    "posterior = svi.run(x_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive distribution we can get samples from\n",
    "trace_pred = TracePredictive(wrapped_model,\n",
    "                             posterior,\n",
    "                             num_samples=1000)\n",
    "post_pred = trace_pred.run(x_data, None)\n",
    "post_summary = summary(post_pred, sites= ['prediction', 'obs'])\n",
    "mu = post_summary[\"prediction\"]\n",
    "y = post_summary[\"obs\"]\n",
    "predictions = pd.DataFrame({\n",
    "    \"cont_africa\": x_data[:, 0],\n",
    "    \"rugged\": x_data[:, 1],\n",
    "    \"mu_mean\": mu[\"mean\"],\n",
    "    \"mu_perc_5\": mu[\"5%\"],\n",
    "    \"mu_perc_95\": mu[\"95%\"],\n",
    "    \"y_mean\": y[\"mean\"],\n",
    "    \"y_perc_5\": y[\"5%\"],\n",
    "    \"y_perc_95\": y[\"95%\"],\n",
    "    \"true_gdp\": y_data,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "african_nations = predictions[predictions[\"cont_africa\"] == 1]\n",
    "non_african_nations = predictions[predictions[\"cont_africa\"] == 0]\n",
    "african_nations = african_nations.sort_values(by=[\"rugged\"])\n",
    "non_african_nations = non_african_nations.sort_values(by=[\"rugged\"])\n",
    "fig.suptitle(\"Regression line 90% CI\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"mu_mean\"])\n",
    "ax[0].fill_between(non_african_nations[\"rugged\"],\n",
    "                   non_african_nations[\"mu_perc_5\"],\n",
    "                   non_african_nations[\"mu_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "idx = np.argsort(african_nations[\"rugged\"])\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"mu_mean\"])\n",
    "ax[1].fill_between(african_nations[\"rugged\"],\n",
    "                   african_nations[\"mu_perc_5\"],\n",
    "                   african_nations[\"mu_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "fig.suptitle(\"Posterior predictive distribution with 90% CI\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"y_mean\"])\n",
    "ax[0].fill_between(non_african_nations[\"rugged\"],\n",
    "                   non_african_nations[\"y_perc_5\"],\n",
    "                   non_african_nations[\"y_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "idx = np.argsort(african_nations[\"rugged\"])\n",
    "\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"y_mean\"])\n",
    "ax[1].fill_between(african_nations[\"rugged\"],\n",
    "                   african_nations[\"y_perc_5\"],\n",
    "                   african_nations[\"y_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to prepend `module$$$` to all parameters of nn.Modules since\n",
    "# that is how they are stored in the ParamStore\n",
    "weight = get_marginal(posterior, ['module$$$linear.weight']).squeeze(1).squeeze(1)\n",
    "factor = get_marginal(posterior, ['module$$$factor'])\n",
    "gamma_within_africa = weight[:, 1] + factor.squeeze(1)\n",
    "gamma_outside_africa = weight[:, 1]\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.distplot(gamma_within_africa, kde_kws={\"label\": \"African nations\"},)\n",
    "sns.distplot(gamma_outside_africa, kde_kws={\"label\": \"Non-African nations\"})\n",
    "fig.suptitle(\"Density of Slope : log(GDP) vs. Terrain Ruggedness\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from CRF implementation https://raw.githubusercontent.com/kmkurn/pytorch-crf/master/torchcrf/__init__.py\n",
    "class CRF(nn.Module):\n",
    "    \"\"\"Conditional random field.\n",
    "\n",
    "    This module implements a conditional random field [LMP01]_. The forward computation\n",
    "    of this class computes the log likelihood of the given sequence of tags and\n",
    "    emission score tensor. This class also has `~CRF.decode` method which finds\n",
    "    the best tag sequence given an emission score tensor using `Viterbi algorithm`_.\n",
    "\n",
    "    Args:\n",
    "        num_tags: Number of tags.\n",
    "        batch_first: Whether the first dimension corresponds to the size of a minibatch.\n",
    "\n",
    "    Attributes:\n",
    "        start_transitions (`~torch.nn.Parameter`): Start transition score tensor of size\n",
    "            ``(num_tags,)``.\n",
    "        end_transitions (`~torch.nn.Parameter`): End transition score tensor of size\n",
    "            ``(num_tags,)``.\n",
    "        transitions (`~torch.nn.Parameter`): Transition score tensor of size\n",
    "            ``(num_tags, num_tags)``.\n",
    "\n",
    "\n",
    "    .. [LMP01] Lafferty, J., McCallum, A., Pereira, F. (2001).\n",
    "       \"Conditional random fields: Probabilistic models for segmenting and\n",
    "       labeling sequence data\". *Proc. 18th International Conf. on Machine\n",
    "       Learning*. Morgan Kaufmann. pp. 282–289.\n",
    "\n",
    "    .. _Viterbi algorithm: https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_tags: int, batch_first: bool = False) -> None:\n",
    "        if num_tags <= 0:\n",
    "            raise ValueError(f'invalid number of tags: {num_tags}')\n",
    "        super().__init__()\n",
    "        self.num_tags = num_tags\n",
    "        self.batch_first = batch_first\n",
    "        self.start_transitions = nn.Parameter(torch.empty(num_tags))\n",
    "        self.end_transitions = nn.Parameter(torch.empty(num_tags))\n",
    "        self.transitions = nn.Parameter(torch.empty(num_tags, num_tags))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Initialize the transition parameters.\n",
    "\n",
    "        The parameters will be initialized randomly from a uniform distribution\n",
    "        between -0.1 and 0.1.\n",
    "        \"\"\"\n",
    "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}(num_tags={self.num_tags})'\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            emissions: torch.Tensor,\n",
    "            tags: torch.LongTensor,\n",
    "            mask: Optional[torch.ByteTensor] = None,\n",
    "            reduction: str = 'sum',\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute the conditional log likelihood of a sequence of tags given emission scores.\n",
    "\n",
    "        Args:\n",
    "            emissions (`~torch.Tensor`): Emission score tensor of size\n",
    "                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``,\n",
    "                ``(batch_size, seq_length, num_tags)`` otherwise.\n",
    "            tags (`~torch.LongTensor`): Sequence of tags tensor of size\n",
    "                ``(seq_length, batch_size)`` if ``batch_first`` is ``False``,\n",
    "                ``(batch_size, seq_length)`` otherwise.\n",
    "            mask (`~torch.ByteTensor`): Mask tensor of size ``(seq_length, batch_size)``\n",
    "                if ``batch_first`` is ``False``, ``(batch_size, seq_length)`` otherwise.\n",
    "            reduction: Specifies  the reduction to apply to the output:\n",
    "                ``none|sum|mean|token_mean``. ``none``: no reduction will be applied.\n",
    "                ``sum``: the output will be summed over batches. ``mean``: the output will be\n",
    "                averaged over batches. ``token_mean``: the output will be averaged over tokens.\n",
    "\n",
    "        Returns:\n",
    "            `~torch.Tensor`: The log likelihood. This will have size ``(batch_size,)`` if\n",
    "            reduction is ``none``, ``()`` otherwise.\n",
    "        \"\"\"\n",
    "        self._validate(emissions, tags=tags, mask=mask)\n",
    "        if reduction not in ('none', 'sum', 'mean', 'token_mean'):\n",
    "            raise ValueError(f'invalid reduction: {reduction}')\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(tags, dtype=torch.uint8)\n",
    "\n",
    "        if self.batch_first:\n",
    "            emissions = emissions.transpose(0, 1)\n",
    "            tags = tags.transpose(0, 1)\n",
    "            mask = mask.transpose(0, 1)\n",
    "\n",
    "        # shape: (batch_size,)\n",
    "        numerator = self._compute_score(emissions, tags, mask)\n",
    "        # shape: (batch_size,)\n",
    "        denominator = self._compute_normalizer(emissions, mask)\n",
    "        # shape: (batch_size,)\n",
    "        llh = numerator - denominator\n",
    "\n",
    "        if reduction == 'none':\n",
    "            return llh\n",
    "        if reduction == 'sum':\n",
    "            return llh.sum()\n",
    "        if reduction == 'mean':\n",
    "            return llh.mean()\n",
    "        assert reduction == 'token_mean'\n",
    "        return llh.sum() / mask.float().sum()\n",
    "\n",
    "    def decode(self, emissions: torch.Tensor,\n",
    "               mask: Optional[torch.ByteTensor] = None) -> List[List[int]]:\n",
    "        \"\"\"Find the most likely tag sequence using Viterbi algorithm.\n",
    "\n",
    "        Args:\n",
    "            emissions (`~torch.Tensor`): Emission score tensor of size\n",
    "                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``,\n",
    "                ``(batch_size, seq_length, num_tags)`` otherwise.\n",
    "            mask (`~torch.ByteTensor`): Mask tensor of size ``(seq_length, batch_size)``\n",
    "                if ``batch_first`` is ``False``, ``(batch_size, seq_length)`` otherwise.\n",
    "\n",
    "        Returns:\n",
    "            List of list containing the best tag sequence for each batch.\n",
    "        \"\"\"\n",
    "        self._validate(emissions, mask=mask)\n",
    "        if mask is None:\n",
    "            mask = emissions.new_ones(emissions.shape[:2], dtype=torch.uint8)\n",
    "\n",
    "        if self.batch_first:\n",
    "            emissions = emissions.transpose(0, 1)\n",
    "            mask = mask.transpose(0, 1)\n",
    "\n",
    "        return self._viterbi_decode(emissions, mask)\n",
    "\n",
    "    def _validate(\n",
    "            self,\n",
    "            emissions: torch.Tensor,\n",
    "            tags: Optional[torch.LongTensor] = None,\n",
    "            mask: Optional[torch.ByteTensor] = None) -> None:\n",
    "        if emissions.dim() != 3:\n",
    "            raise ValueError(f'emissions must have dimension of 3, got {emissions.dim()}')\n",
    "        if emissions.size(2) != self.num_tags:\n",
    "            raise ValueError(\n",
    "                f'expected last dimension of emissions is {self.num_tags}, '\n",
    "                f'got {emissions.size(2)}')\n",
    "\n",
    "        if tags is not None:\n",
    "            if emissions.shape[:2] != tags.shape:\n",
    "                raise ValueError(\n",
    "                    'the first two dimensions of emissions and tags must match, '\n",
    "                    f'got {tuple(emissions.shape[:2])} and {tuple(tags.shape)}')\n",
    "\n",
    "        if mask is not None:\n",
    "            if emissions.shape[:2] != mask.shape:\n",
    "                raise ValueError(\n",
    "                    'the first two dimensions of emissions and mask must match, '\n",
    "                    f'got {tuple(emissions.shape[:2])} and {tuple(mask.shape)}')\n",
    "            no_empty_seq = not self.batch_first and mask[0].all()\n",
    "            no_empty_seq_bf = self.batch_first and mask[:, 0].all()\n",
    "            if not no_empty_seq and not no_empty_seq_bf:\n",
    "                raise ValueError('mask of the first timestep must all be on')\n",
    "\n",
    "    def _compute_score(\n",
    "            self, emissions: torch.Tensor, tags: torch.LongTensor,\n",
    "            mask: torch.ByteTensor) -> torch.Tensor:\n",
    "        # emissions: (seq_length, batch_size, num_tags)\n",
    "        # tags: (seq_length, batch_size)\n",
    "        # mask: (seq_length, batch_size)\n",
    "        assert emissions.dim() == 3 and tags.dim() == 2\n",
    "        assert emissions.shape[:2] == tags.shape\n",
    "        assert emissions.size(2) == self.num_tags\n",
    "        assert mask.shape == tags.shape\n",
    "        assert mask[0].all()\n",
    "\n",
    "        seq_length, batch_size = tags.shape\n",
    "        mask = mask.float()\n",
    "\n",
    "        # Start transition score and first emission\n",
    "        # shape: (batch_size,)\n",
    "        score = self.start_transitions[tags[0]]\n",
    "        score += emissions[0, torch.arange(batch_size), tags[0]]\n",
    "\n",
    "        for i in range(1, seq_length):\n",
    "            # Transition score to next tag, only added if next timestep is valid (mask == 1)\n",
    "            # shape: (batch_size,)\n",
    "            score += self.transitions[tags[i - 1], tags[i]] * mask[i]\n",
    "\n",
    "            # Emission score for next tag, only added if next timestep is valid (mask == 1)\n",
    "            # shape: (batch_size,)\n",
    "            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]\n",
    "\n",
    "        # End transition score\n",
    "        # shape: (batch_size,)\n",
    "        seq_ends = mask.long().sum(dim=0) - 1\n",
    "        # shape: (batch_size,)\n",
    "        last_tags = tags[seq_ends, torch.arange(batch_size)]\n",
    "        # shape: (batch_size,)\n",
    "        score += self.end_transitions[last_tags]\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _compute_normalizer(\n",
    "            self, emissions: torch.Tensor, mask: torch.ByteTensor) -> torch.Tensor:\n",
    "        # emissions: (seq_length, batch_size, num_tags)\n",
    "        # mask: (seq_length, batch_size)\n",
    "        assert emissions.dim() == 3 and mask.dim() == 2\n",
    "        assert emissions.shape[:2] == mask.shape\n",
    "        assert emissions.size(2) == self.num_tags\n",
    "        assert mask[0].all()\n",
    "\n",
    "        seq_length = emissions.size(0)\n",
    "\n",
    "        # Start transition score and first emission; score has size of\n",
    "        # (batch_size, num_tags) where for each batch, the j-th column stores\n",
    "        # the score that the first timestep has tag j\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score = self.start_transitions + emissions[0]\n",
    "\n",
    "        for i in range(1, seq_length):\n",
    "            # Broadcast score for every possible next tag\n",
    "            # shape: (batch_size, num_tags, 1)\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "\n",
    "            # Broadcast emission score for every possible current tag\n",
    "            # shape: (batch_size, 1, num_tags)\n",
    "            broadcast_emissions = emissions[i].unsqueeze(1)\n",
    "\n",
    "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
    "            # for each sample, entry at row i and column j stores the sum of scores of all\n",
    "            # possible tag sequences so far that end with transitioning from tag i to tag j\n",
    "            # and emitting\n",
    "            # shape: (batch_size, num_tags, num_tags)\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
    "\n",
    "            # Sum over all possible current tags, but we're in score space, so a sum\n",
    "            # becomes a log-sum-exp: for each sample, entry i stores the sum of scores of\n",
    "            # all possible tag sequences so far, that end in tag i\n",
    "            # shape: (batch_size, num_tags)\n",
    "            next_score = torch.logsumexp(next_score, dim=1)\n",
    "\n",
    "            # Set score to the next score if this timestep is valid (mask == 1)\n",
    "            # shape: (batch_size, num_tags)\n",
    "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
    "\n",
    "        # End transition score\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score += self.end_transitions\n",
    "\n",
    "        # Sum (log-sum-exp) over all possible tags\n",
    "        # shape: (batch_size,)\n",
    "        return torch.logsumexp(score, dim=1)\n",
    "\n",
    "    def _viterbi_decode(self, emissions: torch.FloatTensor,\n",
    "                        mask: torch.ByteTensor) -> List[List[int]]:\n",
    "        # emissions: (seq_length, batch_size, num_tags)\n",
    "        # mask: (seq_length, batch_size)\n",
    "        assert emissions.dim() == 3 and mask.dim() == 2\n",
    "        assert emissions.shape[:2] == mask.shape\n",
    "        assert emissions.size(2) == self.num_tags\n",
    "        assert mask[0].all()\n",
    "\n",
    "        seq_length, batch_size = mask.shape\n",
    "\n",
    "        # Start transition and first emission\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score = self.start_transitions + emissions[0]\n",
    "        history = []\n",
    "\n",
    "        # score is a tensor of size (batch_size, num_tags) where for every batch,\n",
    "        # value at column j stores the score of the best tag sequence so far that ends\n",
    "        # with tag j\n",
    "        # history saves where the best tags candidate transitioned from; this is used\n",
    "        # when we trace back the best tag sequence\n",
    "\n",
    "        # Viterbi algorithm recursive case: we compute the score of the best tag sequence\n",
    "        # for every possible next tag\n",
    "        for i in range(1, seq_length):\n",
    "            # Broadcast viterbi score for every possible next tag\n",
    "            # shape: (batch_size, num_tags, 1)\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "\n",
    "            # Broadcast emission score for every possible current tag\n",
    "            # shape: (batch_size, 1, num_tags)\n",
    "            broadcast_emission = emissions[i].unsqueeze(1)\n",
    "\n",
    "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
    "            # for each sample, entry at row i and column j stores the score of the best\n",
    "            # tag sequence so far that ends with transitioning from tag i to tag j and emitting\n",
    "            # shape: (batch_size, num_tags, num_tags)\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
    "\n",
    "            # Find the maximum score over all possible current tag\n",
    "            # shape: (batch_size, num_tags)\n",
    "            next_score, indices = next_score.max(dim=1)\n",
    "\n",
    "            # Set score to the next score if this timestep is valid (mask == 1)\n",
    "            # and save the index that produces the next score\n",
    "            # shape: (batch_size, num_tags)\n",
    "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
    "            history.append(indices)\n",
    "\n",
    "        # End transition score\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score += self.end_transitions\n",
    "\n",
    "        # Now, compute the best path for each sample\n",
    "\n",
    "        # shape: (batch_size,)\n",
    "        seq_ends = mask.long().sum(dim=0) - 1\n",
    "        best_tags_list = []\n",
    "\n",
    "        for idx in range(batch_size):\n",
    "            # Find the tag which maximizes the score at the last timestep; this is our best tag\n",
    "            # for the last timestep\n",
    "            _, best_last_tag = score[idx].max(dim=0)\n",
    "            best_tags = [best_last_tag.item()]\n",
    "\n",
    "            # We trace back where the best last tag comes from, append that to our best tag\n",
    "            # sequence, and trace it back again, and so on\n",
    "            for hist in reversed(history[:seq_ends[idx]]):\n",
    "                best_last_tag = hist[idx][best_tags[-1]]\n",
    "                best_tags.append(best_last_tag.item())\n",
    "\n",
    "            # Reverse the order because we start from the last timestep\n",
    "            best_tags.reverse()\n",
    "            best_tags_list.append(best_tags)\n",
    "\n",
    "        return best_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from PyTorch tutorials: https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        # tagset_size includes <START> and <STOP>\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "        # embedding matrix\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # project the output of the LSTM at each state into tag space. Input to CRF model.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        # this is a right stochastic matrix if row sums to 1\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best ptranath.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        # Lafferty et al. 2001\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "\n",
    "# Make up some training data\n",
    "training_data = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n",
    "\n",
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(14.0426), [2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "(tensor(34.0644), [0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(\n",
    "        300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(model(precheck_sent))\n",
    "# We got it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4d016fa20>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dev_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
