{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Uniform, Delta\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.distributions.util import logsumexp\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "import pyro.optim as optim\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "# assert pyro.__version__.startswith('0.3.1')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://d2fefpcigoriu7.cloudfront.net/datasets/rugged_data.csv\"\n",
    "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 170 entries, 2 to 233\n",
      "Data columns (total 3 columns):\n",
      "cont_africa    170 non-null int64\n",
      "rugged         170 non-null float64\n",
      "rgdppc_2000    170 non-null float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 5.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4649e49198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df[\"rugged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS(nn.Module):\n",
    "    def __init__(self, num_params):\n",
    "        super(OLS, self).__init__()\n",
    "        self.linear = nn.Linear(num_params, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OLS(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.rand(1000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = x_data @ torch.tensor([[2],[-1], [1]], dtype=torch.float32) + torch.tensor(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li/.virtualenvs/pp/lib/python3.6/site-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([1000, 1])) that is different to the input size (torch.Size([1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 491375.2812\n",
      "[iteration 0100] loss: 490273.1250\n",
      "[iteration 0150] loss: 490260.5000\n",
      "[iteration 0200] loss: 490260.5000\n",
      "[iteration 0250] loss: 490260.5000\n",
      "[iteration 0300] loss: 490260.5000\n",
      "[iteration 0350] loss: 490260.4688\n",
      "[iteration 0400] loss: 490260.4688\n",
      "[iteration 0450] loss: 490260.4688\n",
      "[iteration 0500] loss: 490260.4688\n",
      "[iteration 0550] loss: 490260.4688\n",
      "[iteration 0600] loss: 490260.4688\n",
      "[iteration 0650] loss: 490260.4688\n",
      "[iteration 0700] loss: 490260.4688\n",
      "[iteration 0750] loss: 490260.4688\n",
      "[iteration 0800] loss: 490260.4688\n",
      "[iteration 0850] loss: 490260.4688\n",
      "[iteration 0900] loss: 490260.4688\n",
      "[iteration 0950] loss: 490260.4688\n",
      "[iteration 1000] loss: 490260.4688\n",
      "Learned parameters:\n",
      "linear.weight [[-2.3307880e-08 -2.5608076e-08 -2.4100025e-08]]\n",
      "linear.bias [0.9827749]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "num_iterations = 1000\n",
    "\n",
    "\n",
    "def main():\n",
    "    for j in range(num_iterations):\n",
    "        # run the model forward on the data\n",
    "        y_pred = model(x_data).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y_data)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        if (j + 1) % 50 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.data.numpy())\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    # weight and bias priors\n",
    "    w_prior = Normal(torch.zeros(1, 2), torch.ones(1, 2)).to_event(1)\n",
    "    b_prior = Normal(torch.tensor([[8.]]), torch.tensor([[1000.]])).to_event(1)\n",
    "    f_prior = Normal(0., 1.)\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior, 'factor': f_prior}\n",
    "    scale = pyro.sample(\"sigma\", Uniform(0., 10.))\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
    "    # sample a nn (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    with pyro.plate(\"map\", len(x_data)):\n",
    "        # run the nn forward on data\n",
    "        prediction_mean = lifted_reg_model(x_data).squeeze(-1)\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\",\n",
    "                    Normal(prediction_mean, scale),\n",
    "                    obs=y_data)\n",
    "        return prediction_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO(), num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-683f0d7ec27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[iteration %04d] loss: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-683f0d7ec27e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# calculate the loss and take a gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[iteration %04d] loss: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[1;32m     51\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 52\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mguide_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[1;32m     44\u001b[0m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/contrib/autoguide/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# if we've never run the model before, do so now so we can inspect the model structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototype_trace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/contrib/autoguide/__init__.py\u001b[0m in \u001b[0;36m_setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoContinuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unconstrained_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond_indep_stacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/contrib/autoguide/__init__.py\u001b[0m in \u001b[0;36m_setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_prototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# run the model so we can inspect its structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototype_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototype_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_subsample_sites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototype_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_wraps\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0m_wraps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wraps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pp/lib/python3.6/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4656d09c749e>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(x_data, y_data)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sigma\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# lift module parameters to random variables sampled from the priors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlifted_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"module\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# sample a nn (which also samples w and b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlifted_reg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlifted_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regression_model' is not defined"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    pyro.clear_param_store()\n",
    "    for j in range(num_iterations):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(x_data, y_data)\n",
    "        if j % 100 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_marginal = lambda traces, sites:EmpiricalMarginal(traces, sites)._get_samples_and_weights()[0].detach().cpu().numpy()\n",
    "\n",
    "def summary(traces, sites):\n",
    "    marginal = get_marginal(traces, sites)\n",
    "    site_stats = {}\n",
    "    for i in range(marginal.shape[1]):\n",
    "        site_name = sites[i]\n",
    "        marginal_site = pd.DataFrame(marginal[:, i]).transpose()\n",
    "        describe = partial(pd.Series.describe, percentiles=[.05, 0.25, 0.5, 0.75, 0.95])\n",
    "        site_stats[site_name] = marginal_site.apply(describe, axis=1) \\\n",
    "            [[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats\n",
    "\n",
    "def wrapped_model(x_data, y_data):\n",
    "    pyro.sample(\"prediction\", Delta(model(x_data, y_data)))\n",
    "\n",
    "posterior = svi.run(x_data, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive distribution we can get samples from\n",
    "trace_pred = TracePredictive(wrapped_model,\n",
    "                             posterior,\n",
    "                             num_samples=1000)\n",
    "post_pred = trace_pred.run(x_data, None)\n",
    "post_summary = summary(post_pred, sites= ['prediction', 'obs'])\n",
    "mu = post_summary[\"prediction\"]\n",
    "y = post_summary[\"obs\"]\n",
    "predictions = pd.DataFrame({\n",
    "    \"cont_africa\": x_data[:, 0],\n",
    "    \"rugged\": x_data[:, 1],\n",
    "    \"mu_mean\": mu[\"mean\"],\n",
    "    \"mu_perc_5\": mu[\"5%\"],\n",
    "    \"mu_perc_95\": mu[\"95%\"],\n",
    "    \"y_mean\": y[\"mean\"],\n",
    "    \"y_perc_5\": y[\"5%\"],\n",
    "    \"y_perc_95\": y[\"95%\"],\n",
    "    \"true_gdp\": y_data,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "african_nations = predictions[predictions[\"cont_africa\"] == 1]\n",
    "non_african_nations = predictions[predictions[\"cont_africa\"] == 0]\n",
    "african_nations = african_nations.sort_values(by=[\"rugged\"])\n",
    "non_african_nations = non_african_nations.sort_values(by=[\"rugged\"])\n",
    "fig.suptitle(\"Regression line 90% CI\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"mu_mean\"])\n",
    "ax[0].fill_between(non_african_nations[\"rugged\"],\n",
    "                   non_african_nations[\"mu_perc_5\"],\n",
    "                   non_african_nations[\"mu_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "idx = np.argsort(african_nations[\"rugged\"])\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"mu_mean\"])\n",
    "ax[1].fill_between(african_nations[\"rugged\"],\n",
    "                   african_nations[\"mu_perc_5\"],\n",
    "                   african_nations[\"mu_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "fig.suptitle(\"Posterior predictive distribution with 90% CI\", fontsize=16)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"y_mean\"])\n",
    "ax[0].fill_between(non_african_nations[\"rugged\"],\n",
    "                   non_african_nations[\"y_perc_5\"],\n",
    "                   non_african_nations[\"y_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[0].plot(non_african_nations[\"rugged\"],\n",
    "           non_african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[0].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"Non African Nations\")\n",
    "idx = np.argsort(african_nations[\"rugged\"])\n",
    "\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"y_mean\"])\n",
    "ax[1].fill_between(african_nations[\"rugged\"],\n",
    "                   african_nations[\"y_perc_5\"],\n",
    "                   african_nations[\"y_perc_95\"],\n",
    "                   alpha=0.5)\n",
    "ax[1].plot(african_nations[\"rugged\"],\n",
    "           african_nations[\"true_gdp\"],\n",
    "           \"o\")\n",
    "ax[1].set(xlabel=\"Terrain Ruggedness Index\",\n",
    "          ylabel=\"log GDP (2000)\",\n",
    "          title=\"African Nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to prepend `module$$$` to all parameters of nn.Modules since\n",
    "# that is how they are stored in the ParamStore\n",
    "weight = get_marginal(posterior, ['module$$$linear.weight']).squeeze(1).squeeze(1)\n",
    "factor = get_marginal(posterior, ['module$$$factor'])\n",
    "gamma_within_africa = weight[:, 1] + factor.squeeze(1)\n",
    "gamma_outside_africa = weight[:, 1]\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.distplot(gamma_within_africa, kde_kws={\"label\": \"African nations\"},)\n",
    "sns.distplot(gamma_outside_africa, kde_kws={\"label\": \"Non-African nations\"})\n",
    "fig.suptitle(\"Density of Slope : log(GDP) vs. Terrain Ruggedness\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from PyTorch tutorials: https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        # tagset_size includes <START> and <STOP>\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        # embedding matrix\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # project the output of the LSTM at each state into tag space. Input to CRF model.\n",
    "        # fully connected layers, emission score per token\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters. Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        # this is NOT a right stochastic matrix whose row sums to 1, simply scores.\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _penalty(self, lda=1e-2, norm=\"l1\"):\n",
    "        w = self.transitions.detach()\n",
    "        w[tag_to_ix[START_TAG], :] = 0\n",
    "        w[:, tag_to_ix[STOP_TAG]] = 0\n",
    "        \n",
    "        if norm == \"l1\":\n",
    "            return w.abs().sum() * lda\n",
    "        elif norm == \"l2\":\n",
    "            return torch.pow(w, 2).sum().sqrt() * lda\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        # output [len(sentences), hidden_dim]\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        # lstm_feats [len(sentence), len(tag_size)] aka emission score\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # feats in shape [len(sentences), len(tag_size)]\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        # insert corresponding index of START_TAG\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            # feat in [hidden_size], emission score from LSTM\n",
    "            score += self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score += self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        # total of emission score and transition score, given the sequence and state transitions.\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best ptranath.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        # Lafferty et al. 2001\n",
    "        # sentences are index-of-vocabulary, so are tags\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        # feats [len(sentence), len(tag_size)]\n",
    "        # probability of the sequence given parameters (of BiLSTM and CRF)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        # if states (i.e. tags) are given, probability of sequence (i.e. pure emission scores)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score + self._penalty()\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_bilou(iterable: List[Dict]) -> Tuple:\n",
    "    for i in iterable:\n",
    "        tokens = i[\"paragraphs\"][0][\"sentences\"][0][\"tokens\"]\n",
    "        words = [token[\"orth\"] for token in tokens]\n",
    "        entities = [token[\"ner\"] for token in tokens]\n",
    "        yield tuple([words, entities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_DIM = 8\n",
    "\n",
    "# Make up some training data\n",
    "# training_data = [(\n",
    "#     \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "#     \"B I I I O O O B I O O\".split()\n",
    "# ), (\n",
    "#     \"georgia tech is a university in georgia\".split(),\n",
    "#     \"B I O O O O B\".split()\n",
    "# )]\n",
    "\n",
    "with open(Path(\"./data/onto.jsonl/onto.train.json\"), \"r\") as f:\n",
    "    raw_train_json = json.load(f)\n",
    "    training_data = list(jsonl_to_bilou(raw_train_json))[:50]\n",
    "\n",
    "# with open(Path(\"./data/onto.jsonl/onto.development.json\"), \"r\") as f:\n",
    "#     raw_dev_json = json.load(f)\n",
    "#     validation_data = list(jsonl_to_bilou(raw_dev_json))\n",
    "\n",
    "word_to_ix = {}\n",
    "tag_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_ix:\n",
    "            tag_to_ix[tag] = len(tag_to_ix)\n",
    "\n",
    "# for sentence, tags in validation_data:\n",
    "#     for word in sentence:\n",
    "#         if word not in word_to_ix:\n",
    "#             word_to_ix[word] = len(word_to_ix)\n",
    "#     for tag in tags:\n",
    "#         if tag not in tag_to_ix:\n",
    "#             tag_to_ix[tag] = len(tag_to_ix)\n",
    "\n",
    "tag_to_ix[START_TAG] = len(tag_to_ix)\n",
    "tag_to_ix[STOP_TAG] = len(tag_to_ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "    print(prepare_sequence(training_data[0][1], tag_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    for k, (sentence, tags) in enumerate(training_data):\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tag_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    for i in range(len(training_data)):\n",
    "        precheck_sent = prepare_sequence(training_data[i][0], word_to_ix)\n",
    "        print(model(precheck_sent))\n",
    "        print(prepare_sequence(training_data[i][1], tag_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = model.transitions.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding = WordEmbeddings(\"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"we are travelling to Washington .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sentence(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s[-2].get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.embed([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[-2].get_embedding().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([token.get_embedding().unsqueeze(0) for token in s], 0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training.log\", \"r\") as f:\n",
    "    no_penalty_0 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_1.log\", \"r\") as f:\n",
    "    no_penalty_1 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l1.log\", \"r\") as f:\n",
    "    l1_penalty_0 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l1_1.log\", \"r\") as f:\n",
    "    l1_penalty_1 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_2.log\", \"r\") as f:\n",
    "    no_penalty_2 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l1_2.log\", \"r\") as f:\n",
    "    l1_penalty_2 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_3.log\", \"r\") as f:\n",
    "    no_penalty_3 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l1_3.log\", \"r\") as f:\n",
    "    l1_penalty_3 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_4.log\", \"r\") as f:\n",
    "    no_penalty_4 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l1_4.log\", \"r\") as f:\n",
    "    l1_penalty_4 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_5.log\", \"r\") as f:\n",
    "    no_penalty_5 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_5.log\", \"r\") as f:\n",
    "    l2_penalty_5 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_6.log\", \"r\") as f:\n",
    "    no_penalty_6 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_6.log\", \"r\") as f:\n",
    "    l2_penalty_6 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_7.log\", \"r\") as f:\n",
    "    no_penalty_7 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_7.log\", \"r\") as f:\n",
    "    l2_penalty_7 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_8.log\", \"r\") as f:\n",
    "    no_penalty_8 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_w_8.log\", \"r\") as f:\n",
    "    l2_penalty_w_8 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_9.log\", \"r\") as f:\n",
    "    no_penalty_9 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_w_9.log\", \"r\") as f:\n",
    "    l2_penalty_w_9 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_10.log\", \"r\") as f:\n",
    "    no_penalty_10 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_w_10.log\", \"r\") as f:\n",
    "    l2_penalty_w_10 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_11.log\", \"r\") as f:\n",
    "    no_penalty_11 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_l2_w_11.log\", \"r\") as f:\n",
    "    l2_penalty_w_11 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_scores(lines):\n",
    "    _breaker = \"MACRO_AVG: acc\"\n",
    "    CAP = False\n",
    "    sep2 = \" - \"\n",
    "    sep3 = \": \"\n",
    "    summary = {}\n",
    "    for l in lines:\n",
    "        if _breaker in l:\n",
    "            CAP = True\n",
    "            continue\n",
    "        if CAP:\n",
    "            try:\n",
    "                sep1 = l.index(\"tp:\")\n",
    "            except ValueError:\n",
    "                CAP = False\n",
    "                continue\n",
    "            l = l.strip()\n",
    "            entity, rest = l[:sep1].strip(), l[sep1:]\n",
    "            summary[entity] = dict([i.split(sep3) for i in rest.split(sep2)])\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_objects = [i for i in locals() if \"penalty\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_penalty = [i for i in p_objects if i.startswith(\"l\") and \"_penalty\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_penalty = [i for i in p_objects if \"no_penalty\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_results(penalty, no_penalty):\n",
    "    p_lst = []\n",
    "    no_p_lst = []\n",
    "\n",
    "    for k, (p, no_p) in enumerate(zip(penalty, no_penalty)):\n",
    "        \n",
    "        p_df = _get_scores(eval(p))\n",
    "        p_df = pd.DataFrame(p_df)\n",
    "        p_df[\"EXPERIMENT\"] = k\n",
    "        p_df[\"PENALTY\"] = True\n",
    "        p_lst.append(p_df)\n",
    "        \n",
    "        df = _get_scores(eval(no_p))\n",
    "        df = pd.DataFrame(df)\n",
    "        df[\"EXPERIMENT\"] = k\n",
    "        df[\"PENALTY\"] = False\n",
    "        no_p_lst.append(df)\n",
    "\n",
    "    rv = pd.concat(p_lst + no_p_lst)\n",
    "    rv = rv.drop(rv.index.difference([\"f1-score\"]), axis=0).reset_index(drop=True)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_penalty_0',\n",
       " 'l1_penalty_1',\n",
       " 'l1_penalty_2',\n",
       " 'l1_penalty_3',\n",
       " 'l1_penalty_4',\n",
       " 'l2_penalty_5',\n",
       " 'l2_penalty_6',\n",
       " 'l2_penalty_7',\n",
       " 'l2_penalty_w_8',\n",
       " 'l2_penalty_w_9',\n",
       " 'l2_penalty_w_10',\n",
       " 'l2_penalty_w_11']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_penalty_0',\n",
       " 'no_penalty_1',\n",
       " 'no_penalty_2',\n",
       " 'no_penalty_3',\n",
       " 'no_penalty_4',\n",
       " 'no_penalty_5',\n",
       " 'no_penalty_6',\n",
       " 'no_penalty_7',\n",
       " 'no_penalty_8',\n",
       " 'no_penalty_9',\n",
       " 'no_penalty_10',\n",
       " 'no_penalty_11']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "assm_df = assemble_results(with_penalty, without_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = [\"ORG\",\n",
    "\"PERSON\",\n",
    "\"GPE\",\n",
    "\"DATE\",\n",
    "\"CARDINAL\",\n",
    "\"NORP\",\n",
    "\"MONEY\",\n",
    "\"PERCENT\",\n",
    "\"ORDINAL\",\n",
    "\"LOC\",\n",
    "\"TIME\",\n",
    "\"WORK_OF_ART\",\n",
    "\"QUANTITY\",\n",
    "\"FAC\",\n",
    "\"EVENT\",\n",
    "\"PRODUCT\",\n",
    "\"LAW\",\n",
    "\"LANGUAGE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = set(ents).difference(set(ents[:2] + ents[-7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CARDINAL',\n",
       " 'DATE',\n",
       " 'GPE',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'PERCENT',\n",
       " 'TIME'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = assm_df.loc[assm_df[\"EXPERIMENT\"] >= 8, assm_df.columns.difference(lst)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"PENALTY\": \"PENALTY&WEIGHTS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = df.melt(id_vars=[\"EXPERIMENT\", \"PENALTY&WEIGHTS\"], var_name=\"ENTITY\", value_name=\"f1-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df[\"f1-score\"] = long_df[\"f1-score\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "sns.boxplot(x=\"ENTITY\", y=\"f1-score\", hue=\"PENALTY&WEIGHTS\", data=long_df)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
