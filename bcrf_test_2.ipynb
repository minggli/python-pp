{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyro, Bayesian analysis, and attempt on BCRF (Qi et al 2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Normal, Uniform\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS(nn.Module):\n",
    "    def __init__(self, p: int):\n",
    "        super(OLS, self).__init__()\n",
    "        # linear transformation in Pytorch takes in x as row vector, strangely\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x_i is a row vector, where its elements are random variables.\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://d2fefpcigoriu7.cloudfront.net/datasets/rugged_data.csv\"\n",
    "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
    "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(df.values, dtype=torch.float)\n",
    "x_data, y_data = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    _ols = OLS(2)\n",
    "    # weight and bias priors\n",
    "    w_prior = Normal(torch.zeros(1, 2), torch.ones(1, 2)).to_event(1)\n",
    "    b_prior = Normal(torch.tensor([[8.]]), torch.tensor([[1000.]])).to_event(1)\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "    lifted_module = pyro.random_module(\"blr\", _ols, priors)\n",
    "    # sample a nn (which also samples w and b)\n",
    "    blr = lifted_module()\n",
    "    scale = pyro.sample(\"sigma\", Uniform(0., 10.))\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "\n",
    "    with pyro.plate(\"map\", len(x_data)):\n",
    "        # run the nn forward on data\n",
    "        prediction_mean = blr(x_data).squeeze(-1)\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\",\n",
    "                    Normal(prediction_mean, scale),\n",
    "                    obs=y_data)\n",
    "        return prediction_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO(), num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 4.2338\n",
      "[iteration 0101] loss: 3.4378\n",
      "[iteration 0201] loss: 3.1478\n",
      "[iteration 0301] loss: 2.8859\n",
      "[iteration 0401] loss: 2.5679\n",
      "[iteration 0501] loss: 2.0416\n",
      "[iteration 0601] loss: 1.5309\n",
      "[iteration 0701] loss: 1.5022\n",
      "[iteration 0801] loss: 1.5009\n",
      "[iteration 0901] loss: 1.4951\n",
      "[iteration 1001] loss: 1.5044\n",
      "[iteration 1101] loss: 1.4890\n",
      "[iteration 1201] loss: 1.5016\n",
      "[iteration 1301] loss: 1.4905\n",
      "[iteration 1401] loss: 1.4908\n",
      "[iteration 1501] loss: 1.4950\n",
      "[iteration 1601] loss: 1.4897\n",
      "[iteration 1701] loss: 1.4964\n",
      "[iteration 1801] loss: 1.4984\n",
      "[iteration 1901] loss: 1.4918\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "for j in range(2000):\n",
    "    loss = svi.step(x_data, y_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_loc tensor([-1.3984, -0.0836,  9.0006, -2.2263], requires_grad=True)\n",
      "auto_scale tensor([0.1713, 0.0415, 0.0728, 0.0754], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
